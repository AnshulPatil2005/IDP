# docker-compose.yml (Compose V2: you can omit 'version:')
services:
  redis:
    image: redis:7
    command: ["redis-server", "--appendonly", "yes"]
    ports: ["6379:6379"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 20
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"   # HTTP
      - "6334:6334"   # gRPC (optional)
    volumes:
      - qdrant_storage:/qdrant/storage
    healthcheck:
      test: ["CMD", "wget", "-q", "http://localhost:6333/readyz", "-O", "-"]
      interval: 5s
      timeout: 3s
      retries: 30
    restart: unless-stopped
  ollama:
    image: ollama/ollama:latest
    ports: ["11434:11434"]
    volumes:
      - ollama:/root/.ollama
    healthcheck:
      # Use the built-in CLI; it returns non-zero until the API is ready
      test: ["CMD-SHELL", "ollama list >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 20s
    restart: unless-stopped

  api:
    image: python:3.11-slim
    working_dir: /app
    volumes: ["./backend:/app", "./configs:/configs"]
    environment:
      REDIS_URL: redis://redis:6379/0
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/1
      CELERY_BROKER_CONNECTION_RETRY_ON_STARTUP: "true"
      LLM_PROVIDER: ollama
      LLM_MODEL: llama3:8b
      OLLAMA_BASE: http://ollama:11434
      PYTHONPATH: /app
    command: >
      bash -lc "pip install -r requirements.txt &&
                uvicorn app.main:app --host 0.0.0.0 --port 8000"
    ports: ["8000:8000"]
    depends_on:
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    restart: unless-stopped

  worker:
    image: python:3.11-slim
    working_dir: /app
    volumes: ["./backend:/app", "./configs:/configs"]
    environment:
      PYTHONPATH: /app
      REDIS_URL: redis://redis:6379/0
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/1
      CELERY_BROKER_CONNECTION_RETRY_ON_STARTUP: "true"
      LLM_PROVIDER: ollama
      LLM_MODEL: llama3:8b
      OLLAMA_BASE: http://ollama:11434
    command: >
      bash -lc "pip install -r requirements.txt &&
                celery -A app.workers.celery_app:celery worker -l info"
    depends_on:
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
      api:
        condition: service_started
    restart: unless-stopped

volumes:
  ollama: {}
  qdrant_storage:
    driver: local
